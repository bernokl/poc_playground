#+TITLE: Following kasten.io intro
The goal is to repeat the lab to run local, to give you a local sandbox with templates alread provided.
Following https://learning.kasten.io/kubernetes/labs/first-kubernetes-cluster/lessons/lab-1/#lab
Modifying it to run local
* Intro
The course actually has a very nice overview of all the basic components
I chose not to repeat everything here, instead I encourage you to go through the start of the lab
Control plane consists of 3 processes:
- kube-apiserver
- kube-controller-manager
- etcd
- kube-scheduler
Non-control plan node runs 2 processes:
- kublet
- kube-proxy
* Lets get into the practical
** Create a cluster
*** directly on hosts
The course goes through bare metal instal
We will be using [[file:standUpMinicubeUbuntu2004.org][minikube]], but I am still capturing the steps
Get the signing key.
#+BEGIN_SRC tmux :session s1
curl -fsSLo /usr/share/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
#+END_SRC
Add the k8s apt repo
   #+begin_src tmux :session s1
echo "deb [signed-by=/usr/share/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
   #+end_src
Install needed dependencies
   #+begin_src tmux :session s1
apt update
apt install -y kubelet kubeadm kubectl docker.io
apt-mark hold kubelet kubeadm kubectl
   #+end_src
*** Using minikube
- I used [[file:standUpMinicubeUbuntu2004.org][Minikube]] document and finally ran:
   #+begin_src tmux :session s1
minikube start --nodes 3 --driver=docker
   #+end_src
** Set up the Kubernetes control plane (I did not have to do this because I am using minikube)
   #+BEGIN_SRC json :tangle /tmp/docker-daemon.json
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2"
}
   #+END_SRC
Move it to /etc/docker
   #+BEGIN_src tmux :session s1
sudo cp /tmp/docker-daemon.json /etc/docker/daemon.json
   #+end_src
Confirm
   #+BEGIN_src tmux :session s1
sudo cat /etc/docker/daemon.json
   #+end_src
   #+BEGIN_src tmux :session s1
systemctl enable docker
systemctl daemon-reload
systemctl restart docker
   #+end_src
On the control plane node run this command in order to initialize the kubernets control plane
   #+BEGIN_src tmux :session s1
kubeadm init --ignore-preflight-errors=all
   #+end_src
   #+BEGIN_src tmux :session s1
ls -al $HOME/.kube
   #+end_src
Go grab the kubeconfig that was created as part of the kubeadm init above
Set the ownership to the current logged in user
   #+BEGIN_src tmux :session s1
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config
   #+end_src
** Join nodes to the cluster (I did not have to do this because I am using minikube)
On the control plane run the following
   #+BEGIN_src tmux :session s1
kubeadm token create --print-join-command
   #+end_src
Run the join command you got above on the nodes you want to join to your cluster
It will look somehting like this
#+BEGIN_EXAMPLE
kubeadm join 10.132.1.51:6443 --token mastwu.lgy6pl3904y5pirq --discovery-token-ca-cert-hash sha256:70b77a1205b3611dd6c62456d10a9cb62bb8a957a368d73319268c6851314c26
#+END_EXAMPLE
Lets check on our nodes
   #+BEGIN_src tmux :session s1
kubectl get nodes
   #+end_src
Note the nodes will remain in NotReady status until we configure networking for the nodes
** Setup a kubernetes add-on for networking (I did not have to do this because I am using minikube)
Kubernetes Add-Ons are pods and services that implement cluster features. Pods extend the functionality of Kubernetes. You can install addons for a range of cluster features including Networking and Visualization.
For this example we are going to install weave net
   #+BEGIN_src tmux :session s1
kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"
   #+end_src
Lets watch the weave-net pods come up
   #+BEGIN_src tmux :session s1
watch kubectl get pods --all-namespaces
   #+end_src
Note you will see a pod for each nodes
If you now look at the nodes you will see they are all ready
#+BEGIN_SRC tmux :session s1
kubectl get nodes
#+END_SRC
** Deploy microservices Minikube users start playing along again
Lets go grab some code for the sock shop demo
   #+BEGIN_src tmux :session s1
git clone https://github.com/microservices-demo/microservices-demo.git
   #+end_src
   #+BEGIN_src tmux :session s1
cd microservices-demo/deploy/kubernetes
   #+end_src
   #+BEGIN_src tmux :session s1
kubectl apply -f complete-demo.yaml
   #+end_src
   #+BEGIN_src tmux :session s1
   watch kubectl get pods --namespace sock-shop
   #+end_src
CTRL+C to exit

* Enable ingress controller
   #+BEGIN_src tmux :session s1
minikube addons enable ingress
   #+end_src
I had a bit of a issue here, it ended up revolving around incorrect /etc/resolv.conf entries
These helped me trace it down
#+BEGIN_EXAMPLE
kubectl get pods -A -w
kubectl describe pod ingress-nginx-admission-create-xxxx -n ingress-nginx
#+END_EXAMPLE
* Lets go look at our sock-shop
   #+BEGIN_src tmux :session s1
kubectl get svc -A
   #+end_src
O I see lots of services for sock-shop, but there is one with a NodePort IP called "front end"
   #+BEGIN_src tmux :session s1
kubectl get svc front-end -n sock-shop
   #+end_src
Mine looks like this
   #+BEGIN_EXAMPLE
NAME        TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
front-end   NodePort   10.99.199.219   <none>        80:30001/TCP   38m
   #+END_EXAMPLE
   #+BEGIN_src tmux :session s1
minikube service front-end --url -n sock-shop
   #+end_src
   NICE!!
   #+BEGIN_EXAMPLE
http://192.168.49.2:30001
   #+END_EXAMPLE
